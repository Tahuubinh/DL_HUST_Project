{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb96447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "# tf.random.set_seed(123)\n",
    "# np.random.seed(123)\n",
    "from sklearn import metrics\n",
    "import json \n",
    "import os\n",
    "\n",
    "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
    "    \n",
    "    def mean_absolute_percentage_error(y_true, y_pred): \n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print('Evaluation metric results:-')\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "    print(f'MSE is : {mse}')\n",
    "    print(f'MAE is : {mae}')\n",
    "    print(f'RMSE is : {rmse}')\n",
    "    print(f'MAPE is : {mape}')\n",
    "    print(f'R2 is : {r2}',end='\\n\\n')\n",
    "    return {'mse' : mse, 'mae' : mae, 'rmse' : rmse, 'mape' : mape, 'r2' : r2}\n",
    "\n",
    "# df = pd.read_csv(r'..\\Data\\Panama Electricity\\continuous_dataset_preprocessing.csv', parse_dates= True)\n",
    "df = pd.read_csv(\n",
    "    \"../Data/Panama Electricity/continuous_dataset_preprocessing.csv\",\n",
    "    parse_dates=True,\n",
    ")\n",
    "df[\"datetime\"] = df[\"datetime\"].apply(pd.to_datetime)\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "train_column_names = df.columns.tolist()\n",
    "column_names.remove('datetime')\n",
    "train_column_names.remove('datetime')\n",
    "train_column_names.remove('nat_demand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13e90d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Evaluation metric results:-\n",
      "MSE is : 3650.2973486872593\n",
      "MAE is : 52.13602635091146\n",
      "RMSE is : 60.4176906931013\n",
      "MAPE is : 4.635879672183831\n",
      "R2 is : 0.9111442117401747\n",
      "\n",
      "1/1 [==============================] - 1s 915ms/step\n",
      "Evaluation metric results:-\n",
      "MSE is : 5995.583593784115\n",
      "MAE is : 59.801669230143226\n",
      "RMSE is : 77.43115389676248\n",
      "MAPE is : 5.062179127914524\n",
      "R2 is : 0.8344138422633229\n",
      "\n",
      "1/1 [==============================] - 1s 930ms/step\n",
      "Evaluation metric results:-\n",
      "MSE is : 13711.847599011475\n",
      "MAE is : 92.39930034993489\n",
      "RMSE is : 117.09759860480263\n",
      "MAPE is : 7.836099703865878\n",
      "R2 is : 0.6261160396461398\n",
      "\n",
      "1/1 [==============================] - 1s 867ms/step\n",
      "Evaluation metric results:-\n",
      "MSE is : 22193.224427853667\n",
      "MAE is : 110.65345134277341\n",
      "RMSE is : 148.97390519098863\n",
      "MAPE is : 9.840035350590192\n",
      "R2 is : -0.3703597295573462\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B890A19040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Evaluation metric results:-\n",
      "MSE is : 1486.4981428447936\n",
      "MAE is : 33.5605961669922\n",
      "RMSE is : 38.55513121291112\n",
      "MAPE is : 3.1207728196694293\n",
      "R2 is : 0.7735413472249875\n",
      "\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B88B2DD8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Evaluation metric results:-\n",
      "MSE is : 16242.364416346594\n",
      "MAE is : 110.6642169108073\n",
      "RMSE is : 127.44553509772948\n",
      "MAPE is : 8.755769500544169\n",
      "R2 is : 0.6045148271232401\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Evaluation metric results:-\n",
      "MSE is : 4614.114165912989\n",
      "MAE is : 54.15515546468098\n",
      "RMSE is : 67.92727115020143\n",
      "MAPE is : 4.650826785640411\n",
      "R2 is : 0.856147973654775\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Evaluation metric results:-\n",
      "MSE is : 46794.790946088615\n",
      "MAE is : 168.5434813680013\n",
      "RMSE is : 216.32103676269818\n",
      "MAPE is : 15.677630991308412\n",
      "R2 is : -4.899528579807084\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Evaluation metric results:-\n",
      "MSE is : 10961.967259593925\n",
      "MAE is : 86.86916245524088\n",
      "RMSE is : 104.69941384551264\n",
      "MAPE is : 6.768809172231362\n",
      "R2 is : 0.7077521700501027\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Evaluation metric results:-\n",
      "MSE is : 9494.99780341363\n",
      "MAE is : 84.43864607747399\n",
      "RMSE is : 97.44227934225282\n",
      "MAPE is : 7.2079886554140815\n",
      "R2 is : 0.6956043426108021\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Evaluation metric results:-\n",
      "MSE is : 38873.2453354753\n",
      "MAE is : 156.05961599934895\n",
      "RMSE is : 197.16299179986922\n",
      "MAPE is : 14.416383994502077\n",
      "R2 is : -1.5617906422518049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# day_to_test = '1/1/2019'\n",
    "for month in [*range(1, 12)]:\n",
    "    day = f'1/{month}/2019'\n",
    "    valid = df[df['datetime'] <= '1/1/2019 23:00']\n",
    "    valid = valid[valid['datetime'] > '1/1/2018 23:00']\n",
    "    train = df[df['datetime'] <= '1/1/2018 23:00']\n",
    "    test = df[df['datetime'] > day + ' 23:00']\n",
    "    datatest = df[df['datetime'] <= day + ' 23:00']\n",
    "    version = 1\n",
    "    hist_window = 42 # 12, 18, 24, 30, 36, 42, 48, 54, 60\n",
    "    horizon = 24 # 12, 18, 24, 30, 36\n",
    "    folder_save = f'../Results/GRU/history_{hist_window}_future_{horizon}_version_{version}'\n",
    "\n",
    "    model_path = f'{folder_save}/model.h5' \n",
    "\n",
    "    x_scaler = preprocessing.MinMaxScaler()\n",
    "    y_scaler = preprocessing.MinMaxScaler()\n",
    "    validX = x_scaler.fit_transform(valid[column_names])\n",
    "    validY = y_scaler.fit_transform(valid[['nat_demand']])\n",
    "\n",
    "    Trained_model = tf.keras.models.load_model(model_path)\n",
    "    folder_save = ''\n",
    "\n",
    "    data_test = x_scaler.fit_transform(datatest[column_names].tail(hist_window))\n",
    "    test_rescaled = data_test.reshape(1, data_test.shape[0], data_test.shape[1])\n",
    "\n",
    "    Predicted_results = Trained_model.predict(test_rescaled)\n",
    "    Predicted_results_Inv_trans = y_scaler.inverse_transform(Predicted_results)\n",
    "    metrics_test = timeseries_evaluation_metrics_func(test['nat_demand'][:horizon],Predicted_results_Inv_trans[0])\n",
    "\n",
    "# with open(f\"{folder_save}/metrics_test.json\", \"w\") as outfile:\n",
    "#     json.dump(metrics_test, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e5153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0eb5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85bfdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57265029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c8427e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80a238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda05d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a5cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e403360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e136fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e1334f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
